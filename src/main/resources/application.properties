#kafka集群地址
spring.kafka.bootstrap-servers=192.168.126.128:9092,192.168.126.129:9092,192.168.126.130:9092
#kafka producer配置
#多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
#这个参数指定了必须要有多少个分区副本收到消息,生产者才会认为消息写入是成功的.这个参数对消息丢失的可能性有重要影响
#ack=0,生产者在成功写入消息之前不会等待任何来自服务器的响应.(出现问题时,会导致消息丢失)
#ack=1,表示只要集群的首领节点收到消息,生产者就会收到一个成功响应.如果消息无法到达首领节点(比如首领节点发生了崩溃
#新的首领节点还没有选举出来)生产者会收到一个错误响应.为了避免数据丢失,生产者会重发消息,不过如果一个没有收到消息的
#节点成为新首领,那么消息会丢失
#ack=all或者-1,表示所有的副本收到消息,才认为成功,这种模式最安全.
#spring.kafka.producer.acks=-1
spring.kafka.producer.acks=1
#重试次数
#spring.kafka.producer.retries=0
# 批量大小
spring.kafka.producer.batch-size=16384
# 提交延时
spring.kafka.producer.properties.linger.ms=0
# 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
# linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了

# 生产端缓冲区大小
spring.kafka.producer.buffer-memory = 33554432
# Kafka提供的序列化和反序列化类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

#spring.kafka.producer.transaction-id-prefix=xxx

# 自定义分区器
# spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner


###########【初始化消费者配置】###########
# 默认的消费组ID
spring.kafka.consumer.properties.group.id=defaultConsumerGroup
# 是否自动提交offset
#spring.kafka.consumer.enable-auto-commit=true
# 提交offset延时(接收到消息后多久提交offset)
#spring.kafka.consumer.auto-commit-interval=1000
# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest:重置为分区中最小的offset;
# latest:重置为分区中最新的offset(消费分区中新产生的数据);
# none:只要有一个分区不存在已提交的offset,就抛出异常;
spring.kafka.consumer.auto-offset-reset=latest
# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
#spring.kafka.consumer.properties.session.timeout.ms=120000
# 消费请求超时时间
#spring.kafka.consumer.properties.request.timeout.ms=180000
# Kafka提供的序列化和反序列化类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
# 消费端监听的topic不存在时，项目启动会报错(关掉)
spring.kafka.listener.missing-topics-fatal=false
# 设置批量消费
# spring.kafka.listener.type=batch
# 批量消费每次最多消费多少条消息

#手动提交时,需要配置ack-mode=manual
#spring.kafka.listener.ack-mode=manual

